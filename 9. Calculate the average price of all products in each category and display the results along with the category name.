from pyspark.sql import SparkSession
from pyspark.sql.functions import avg

# Initialize SparkSession
spark = SparkSession.builder.appName("ProductsExample").getOrCreate()

# Read the "Products" table into a DataFrame
products_df = spark.read.format("jdbc").options(
    url="jdbc:mysql://localhost:3306/your_database_name",
    driver="com.mysql.jdbc.Driver",
    dbtable="Products",
    user="your_username",
    password="your_password"
).load()

# Group by category and calculate the average price
average_price_df = products_df.groupBy("category").agg(avg("price").alias("average_price"))

# Display the result
average_price_df.show()
