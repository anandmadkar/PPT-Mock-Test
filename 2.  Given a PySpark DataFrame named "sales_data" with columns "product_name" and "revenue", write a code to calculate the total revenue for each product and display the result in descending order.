from pyspark.sql import SparkSession
from pyspark.sql.functions import sum
from pyspark.sql.window import Window
from pyspark.sql.functions import desc

# Initialize SparkSession
spark = SparkSession.builder.appName("TotalRevenueExample").getOrCreate()

# Calculate total revenue for each product
total_revenue_df = sales_data.groupBy("product_name").agg(sum("revenue").alias("total_revenue"))

# Sort the DataFrame by total revenue in descending order
sorted_df = total_revenue_df.orderBy(desc("total_revenue"))

# Display the result
sorted_df.show()



